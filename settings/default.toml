# -------------------------------------------------------------------------------------------
# Default settings file. 
# Setting files should not include parameters that are not specified in here.
# -------------------------------------------------------------------------------------------
[overwrite]
# Any parameter specified here will be overwritten. Example (string quotes required):
# 'scripts.training_prog.n_training_steps' = 1337

[gammaloop_state]
# Name of the gammaloop state directory. REQUIRED TO BE OVERWRITTEN
state_dir = "/home/nfink/gammaloop/gl_states"
# Name of the state inside state_dir.
state_name = "default"
# Name of the gammaloop integration state, if any
integration_state_name = "default"
# Name of the model file inside the state_name folder
model_name = "model.json"
# Name of the runcard file inside the state_name folder
runcard_name = "run.toml"
# Name of the integration results file inside the integration_state_name folder
integration_result_file = "integration_results.txt"
process_id = 0
integrand_name = "default"

# -------------------------------------------------------------------------------------------
# The type of integrator/integrand/parameterisation is specified under [layered_X.X_type]
# Parameters specified under [layered_X] take precedence over those in [X.X_type]
# For parameterisations, they are provided in reverse order as [layered_parameterisation.Y], 
# where the name of Y does not matter (just don't use duplicates). This means that in order
# to set up a multichanneling layer, which e.g. calls spherical parameterisation, one can do:
# [layered_parameterisation.Y1991]
# parameterisation_type = "spherical"
# [layered_parameterisation.Y75]
# parameterisation_type = "mc_layer"
# -------------------------------------------------------------------------------------------

[layered_integrator]
integrator_type = "madnis"

[layered_integrand]
integrand_type = "gammaloop"
# Number of continuous input dimensions above the expected 3 * n_loop
continuous_dim = 0 
discrete_dims = []
use_f128 = false
n_cores = 1
# Can be one of "real", "imag", "abs"
training_phase = "real"
verbose = false

[layered_parameterisation.layer_0]
parameterisation_type = "momtrop"

[integrator.naive]

[integrator.vegas]

[integrator.madnis]
batch_size = 1024
learning_rate = 1e-3
discrete_model = "transformer"
use_scheduler = true
n_train_for_scheduler = 1000

# Parameters for the transformer model
[integrator.madnis.transformer]
embedding_dim  = 64
feedforward_dim = 256
heads = 8
transformer_layers = 3
mlp_layers = 3
mlp_units = 256

# Parameters for the Flow module
[integrator.madnis.flow_kwargs]
uniform_latent = true
permutations = "log"
layers = 3
units = 32
bins = 10
min_bin_width = 1e-3
min_bin_height = 1e-3
min_bin_derivative = 1e-3

# Haven't bothered with the non-transformer model yet, will use default params set by madnis
[integrator.madnis.made]

[integrand.gammaloop]
# Can set a state manually here, else will use settings from [gammaloop_state]
gammaloop_state_path = "from_state"
process_id = 0
integrand_name = "default"
momentum_space = true
sample_orientations = false

[integrand.test]
sigma = 10.0
const_f = false

[integrand.kaapo]
path_to_example = "default"
# Params are [m_UV, mu, beta]
params = [6.283185307179586, 3.141592653589793, 1.0]
use_prec = true

[integrand.kaapo.symbolica_integrand_kwargs]
force_rebuild = false
stability_tolerance = 1e-5
stability_abs_tolerance = 1e-15
stability_abs_threshold = 1e-12
escalate_large_weight_multiplier = 0.9
escalate_small_momentum_multiplier = 1e-3
escalate_large_momentum_multiplier = 1e3
rotation_seed = 42
n_shots = 3
build_eagerly = true
sum_orientations = true
runtime_summation = false

[integrand.kaapo.symbolica_integrand_prec_kwargs]
prec = 200
stability_tolerance = 1e-3
stability_abs_tolerance = 1e-15
stability_abs_threshold = 1e-12
escalate_large_weight_multiplier = -1.0
escalate_small_momentum_multiplier = -1.0
escalate_large_momentum_multiplier = -1.0
rotation_seed = 42
n_shots = 1
sum_orientations = true
runtime_summation = false

[parameterisation.spherical]
conformal_scale = 1.0
origins = 0.0

[parameterisation.inv_spherical]
conformal_scale = 1.0
origins = 0.0

[parameterisation.kaapo]
mu = [3.141592653589793, 3.141592653589793, 0.0]
a = 0.5
b = 1.0
vary_a = false
a_min = 0.2

[parameterisation.rkaapo]
mu = [3.141592653589793, 3.141592653589793, 0.0]
a = 0.5
b = 1.0
vary_a = false
a_min = 0.2

[parameterisation.mc_layer]
# Choose from 'ose' and 'fermi', for euclidean-propagator-like terms and fermi surface terms, respectively
subtype = "ose"
ose_exponent = 2.0
fermi_exponent = 0.5
# Edges with zero chemical potential will have their fermi suface term set to one.
set_bosonic_edge_to_one = true

[parameterisation.momtrop]
# Can be one of the following:
# false or false equivalent: Uses the values from graph properties
# float: Sets all edge weights to the same value
# list[float]: Specify a weight for each edge. Length must match the number of internal edges.
overwrite_edge_weight = false
# If false, the integrator will not attempt to learn the discrete inputs
sample_discrete = true

[graph]
# If true, will attempt to get the dot graph from the gammaloop state
from_state = true
# If from_state is false, will use this path instead
dot_path = ""
# Can be one of the following:
# "default": Automatically sets a weight, pretty likely to lead to divergent subgraphs
# float: Sets all edge weights to the same value
# list[float]: Specify a weight for each edge. Length must match the number of internal edges.
momtrop_edge_weight = "default"
# Set this to true if the graph has no externals (e.g. thermal integrand examples from kaapo)
is_vacuum = false
# If true, will set graph properties to [graph.graph_properties]
overwrite_graph_properties = false

# The default is set to 1L_6photons graph kinematics
[graph.graph_properties]
edge_src_dst_vertices = [
    [3, 4], 
    [4, 5], 
    [5, 0], 
    [0, 1], 
    [1, 2], 
    [2, 3]
]
edge_masses = [
    1500.0, 
    1500.0,
    1500.0, 
    1500.0, 
    1500.0, 
    1500.0
]
edge_momentum_shifts = [
    [
        -231.8312618377385,
        -659.5630405248305,
        450.2378756570221
    ],
    [
        -231.8312618377385,
        -359.5630405248305,
        50.23787565702207
    ],
    [
        -209.73057155004852,
        -399.64339371651585,
        126.0433066139587
    ],
    [
        -105.8809596665922,
        -97.7096383269757,
        49.54838522679282
    ],
    [
        0.0, 
        0.0, 
        0.0
    ],
    [
        -231.8312618377385,
        -359.5630405248305,
        50.23787565702207
    ]
]
graph_external_vertices = [0, 1, 2, 3, 4, 5]
graph_signature = [
    [1], [1], [1], [1], [1], [1]
]
momtrop_edge_weight = [
    0.555555555555, 
    0.555555555555, 
    0.555555555555,
    0.555555555555, 
    0.555555555555, 
    0.555555555555
]
lmb_array = [
    [0], [1], [2], [3], [4], [5]
]

[model]
# If true, will attempt to get the model from the gammaloop state
from_state = true
# If from_state is false, will use this path instead
model_path = "default"

# Parameters used in the tprog subcommand
[scripts.training_prog]
n_training_steps = 1000
n_samples = 40000
# Number of samples drawn after the training to compute the final result
n_samples_after_training = 100000
# Training steps between callback of loss to console
n_log = 20
# Training steps between drawing n_samples samples to calculate the rel. std. (rsd)
# Will also output the result +- error and rsd to console
n_plot_rsd = 50
# Training steps between plotting the loss
n_plot_loss = 2
